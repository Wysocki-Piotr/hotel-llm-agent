import streamlit as st
import sys
import os

# 1. Dodajemy katalog g贸wny do cie偶ki, aby widzie modu 'src'
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

from langchain_core.messages import HumanMessage
from src.database import init_db
from src.agent import app  # Importujemy skompilowany graf agenta

# 2. Konfiguracja strony
st.set_page_config(
    page_title="Agent Podr贸偶y AI",
    page_icon="锔",
    layout="wide"
)

# 3. Inicjalizacja bazy danych przy starcie
if "db_initialized" not in st.session_state:
    init_db()
    st.session_state["db_initialized"] = True

# 4. Inicjalizacja historii czatu w sesji
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# 5. UI - Pasek boczny (M贸zg Agenta)
with st.sidebar:
    st.title(" M贸zg Agenta")
    st.markdown("---")

    # Placeholder na Plan
    st.subheader(" Plan Dziaania")
    plan_container = st.empty()
    plan_container.info("Czekam na zadanie...")

    st.markdown("---")

    # Placeholder na Logi (Debug)
    st.subheader("Rx Logi / Debug")
    logs_expander = st.expander("Poka偶 logi systemowe", expanded=True)
    with logs_expander:
        logs_container = st.empty()
        logs_text = ""  # Zmienna do akumulacji log贸w

# 6. UI - G贸wny ekran (Czat)
st.title("锔 Asystent Podr贸偶y")
st.caption("Zapytaj o hotele, koszty i waluty w miastach z bazy danych.")

# Wywietlanie historii wiadomoci
for msg in st.session_state["messages"]:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    else:
        st.chat_message("assistant").write(msg["content"])

# 7. Logika G贸wna - Obsuga wejcia u偶ytkownika
if user_input := st.chat_input("Gdzie chcesz jecha?"):
    # Dodaj wiadomo u偶ytkownika do historii
    st.session_state["messages"].append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # Przygotowanie wejcia dla LangGraph
    # Konwertujemy histori Streamlit na format LangChain (HumanMessage/AIMessage)
    # Dla uproszczenia w tym demo wysyamy ca histori jako list,
    # ale w tym miejscu Agent oczekuje listy obiekt贸w BaseMessage.
    # 呕eby nie komplikowa, tworzymy now list wiadomoci na podstawie historii sesji.
    langchain_messages = [HumanMessage(content=m["content"]) for m in st.session_state["messages"] if
                          m["role"] == "user"]

    # Mo偶na te偶 przekaza po prostu ostatni wiadomo i pozwoli LangGraph zarzdza histori wewntrz,
    # ale w Twoim kodzie src/agent.py stan 'messages' jest typu 'add_messages', wic historia si kumuluje.
    # Bezpieczniej przekaza pen histori z sesji Streamlit, jeli chcemy mie kontekst.
    inputs = {
        "messages": langchain_messages,
        "plan": "",
        "logs": []
    }

    # Uruchomienie Agenta (Streaming)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # Spinner sygnalizujcy mylenie
        with st.spinner("Agent analizuje zapytanie..."):

            # Ptla po zdarzeniach z grafu (Planner -> Agent -> Tools -> Agent)
            for output in app.stream(inputs):
                for node_name, value in output.items():

                    # A. Aktualizacja Planu (jeli Planner skoczy prac)
                    if node_name == "planner" and "plan" in value:
                        plan_container.success(value["plan"])

                    # B. Aktualizacja Log贸w (jeli przyszy nowe logi)
                    if "logs" in value:
                        for log in value["logs"]:
                            # Dodajemy nowy log do widoku
                            logs_text += f" {log}\n"
                            logs_container.text(logs_text)

                    # C. Wyapywanie odpowiedzi kocowej
                    if node_name == "agent":
                        last_msg = value["messages"][-1]

                        # Sprawdzamy, czy to odpowied藕 kocowa (nie wywoanie narzdzia)
                        if not last_msg.tool_calls:
                            content = last_msg.content

                            # Obsuga przypadku, gdy Gemini zwraca list sownik贸w (Tw贸j przypadek z surowym JSON)
                            if isinstance(content, list) and len(content) > 0 and isinstance(content[0],
                                                                                             dict) and "text" in \
                                    content[0]:
                                full_response = content[0]["text"]
                            else:
                                full_response = str(content)

                            message_placeholder.markdown(full_response)

    # Zapisanie odpowiedzi asystenta w historii sesji
    if full_response:
        st.session_state["messages"].append({"role": "assistant", "content": full_response})
    else:
        # Fallback, gdyby co poszo nie tak i response by pusty
        st.error("Nie udao si uzyska odpowiedzi od agenta.")